{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation for sentiment analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18b9772b60aca082"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train-Test evaluation set against Review dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df5d61ab807eaa8f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "label_dir = {\n",
    "    \"positive\": [\"data/positive\"],\n",
    "    \"negative\": [\"data/negative\"]\n",
    "}\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for label in label_dir.keys():\n",
    "    for sub_dir in label_dir[label]:\n",
    "        for file in os.listdir(sub_dir):\n",
    "            filepath = sub_dir + os.sep + file\n",
    "            with open(filepath, encoding='utf8', errors='ignore', mode='r') as review:\n",
    "                content = review.read()\n",
    "                data.append(content)\n",
    "                labels.append(label)\n",
    "                \n",
    "# data, labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T17:56:41.886169Z",
     "start_time": "2024-12-19T17:56:41.534618Z"
    }
   },
   "id": "3802312959dc45",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# stemmer for CountVectorizer\n",
    "def stemmed_words(doc):\n",
    "    from nltk.stem.snowball import PorterStemmer\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    p_stemmer = PorterStemmer()\n",
    "    analyzer = CountVectorizer(stop_words=stopwords.words(\"english\"), ngram_range=(1, 2)).build_analyzer()\n",
    "    return (p_stemmer.stem(word.lower()) for word in analyzer(doc.lower()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T17:56:41.895175Z",
     "start_time": "2024-12-19T17:56:41.888902Z"
    }
   },
   "id": "dfcbd647148a1569",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9533333333333334\n",
      "Confusion Matrix:\n",
      " [[213   6]\n",
      " [ 15 216]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.97      0.95       219\n",
      "    positive       0.97      0.94      0.95       231\n",
      "\n",
      "    accuracy                           0.95       450\n",
      "   macro avg       0.95      0.95      0.95       450\n",
      "weighted avg       0.95      0.95      0.95       450\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# get dataset\n",
    "X, y = data, labels\n",
    "\n",
    "# bootstrap to get more data (sample size = 50%)\n",
    "data_sample, label_sample = resample(data, labels, n_samples=int(len(data) * 0.50), random_state=1)\n",
    "\n",
    "# split dataset into training & testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X+data_sample, y+label_sample, test_size=0.3, random_state =42)\n",
    "\n",
    "# text preprocessing and vectorisation\n",
    "vectoriser = TfidfVectorizer(analyzer=stemmed_words)\n",
    "X_train_vec = vectoriser.fit_transform(X_train)\n",
    "\n",
    "# create classifier\n",
    "classifier = MultinomialNB().fit(X_train_vec, y_train)\n",
    "\n",
    "# predict on test set\n",
    "X_test_vec = vectoriser.transform(X_test)\n",
    "y_pred = classifier.predict(X_test_vec)\n",
    "\n",
    "# classifier evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-19T18:14:37.567837Z",
     "start_time": "2024-12-19T18:14:26.900564Z"
    }
   },
   "id": "initial_id",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train-Test evaluation set against new small talk responses"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a677cae0effcc26"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "25"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_positive = [\"I'm great\", \"I feel happy\", \"Everything is awesome\", \"I'm doing well today\", \"I'm so happy today\", \"I'm feeling fantastic\", \"I'm in a good mood\", \"I'm feeling positive\", \"I'm in high spirits\", \"I'm feeling wonderful\", \"Today is a good day\", \"I'm in a very good mood\", \"I'm feeling absolutely great\", \"I'm feeling excellent\", \"I'm doing superb\", \"Feeling really positive today\", \"I'm doing wonderfully\", \"I'm feeling fabulous\", \"I'm doing awesome, thanks\", \"I'm feeling pretty fantastic\", \"I'm in a great place\", \"I'm loving it\", \"I'm feeling energised\", \"I'm having an incredible day\", \"I'm doing amazing\"]\n",
    "\n",
    "new_data_negative = [\"I'm feeling awful\", \"I'm not great today\", \"I'm pretty sad\", \"I'm feeling down\", \"I feel awful\", \"I'm feeling terrible\", \"I'm doing poorly\", \"Iâ€™m having a tough day\", \"I'm feeling depressed\", \"I'm feeling miserable\", \"Everything is bad\", \"I'm feeling so negative\", \"I'm not doing okay today\", \"I'm really upset today\", \"I'm feeling upset\", \"Everything is bad\", \"I'm feeling very down\", \"Everything is just bad\", \"Today is a bad day\", \"I'm feeling really negative\", \"I'm in a bad place\", \"I am not good at all\", \"I am so bad\", \"I feel very bad right now\", \"I am feeling really down\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T18:23:36.826138Z",
     "start_time": "2024-12-19T18:23:36.810230Z"
    }
   },
   "id": "c731c8c6f82fe256",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "Confusion Matrix:\n",
      " [[21  4]\n",
      " [ 4 21]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.84      0.84        25\n",
      "    positive       0.84      0.84      0.84        25\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.84      0.84      0.84        50\n",
      "weighted avg       0.84      0.84      0.84        50\n"
     ]
    }
   ],
   "source": [
    "# get new test sets\n",
    "new_data = new_data_positive + new_data_negative\n",
    "new_labels = [\"positive\"]*len(new_data_positive) + [\"negative\"]*len(new_data_negative)\n",
    "\n",
    "# create new classifier, training all IMBD dataset\n",
    "vectoriser = TfidfVectorizer(analyzer=stemmed_words)\n",
    "X_train_vec = vectoriser.fit_transform(X+data_sample)\n",
    "classifier = MultinomialNB().fit(X_train_vec, y+label_sample)\n",
    "\n",
    "# predict on new test set\n",
    "X_test_vec = vectoriser.transform(new_data)\n",
    "y_pred = classifier.predict(X_test_vec)\n",
    "\n",
    "# classifier evaluation\n",
    "print(\"Accuracy:\", accuracy_score(new_labels, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(new_labels, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(new_labels, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:24:27.754044Z",
     "start_time": "2024-12-19T20:24:16.691409Z"
    }
   },
   "id": "41925fe6b27e2236",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e7597caa486615b7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4587d94b3f4cbace"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "nltkkernel",
   "language": "python",
   "display_name": "NLTKKERNEL"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
